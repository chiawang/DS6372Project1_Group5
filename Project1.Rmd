---
title: "Project 1"
author: "Brandon, Queena"
date: "September 15, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown 
## Objective 1: Display the ability to build regression models using the skills and discussions from Unit 1 and 2.   

```{r read and analyse the data}
library(ggplot2)

## Read in the CSV file
kc_data_df <- read.csv(file="C:/Users/chiawa/DS6372Project1_Group5/kc_house_data.csv", header=TRUE, sep=",")

## Remove all the NAs
kc_cleanData_df <-kc_data_df[rowSums(is.na(kc_data_df)) == 0,]
pairs (~price + bedrooms + bathrooms + sqft_lot + zipcode + view + floors + sqft_living, data = kc_cleanData_df)

## Try a log transformation with every relevant variable logged.
lprice <- log(kc_cleanData_df$price)
lbedrooms<-log(kc_cleanData_df$bedrooms)
lbathrooms<-log(kc_cleanData_df$bathrooms)
lsqft_lot<-log(kc_cleanData_df$sqft_lot)
lzipcode<-log(kc_cleanData_df$zipcode)
lview <- log(kc_cleanData_df$view)
lfloors<-log(kc_cleanData_df$floors)
lsqft_living<-log(kc_cleanData_df$sqft_living)

pairs (~lprice + lbedrooms + lbathrooms + lsqft_lot + lzipcode + lview + lfloors + lsqft_living, data = kc_cleanData_df)


## Try a sqrt transformation with every relevant variable logged.
sqrt_price <- sqrt(kc_cleanData_df$price)
sqrt_bedrooms<-sqrt(kc_cleanData_df$bedrooms)
sqrt_bathrooms<-sqrt(kc_cleanData_df$bathrooms)
sqrt_sqft_lot<-sqrt(kc_cleanData_df$sqft_lot)
sqrt_zipcode<-sqrt(kc_cleanData_df$zipcode)
sqrt_view <- sqrt(kc_cleanData_df$view)
sqrt_floors<-sqrt(kc_cleanData_df$floors)
sqrt_sqft_living<-sqrt(kc_cleanData_df$sqft_living)

pairs (~sqrt_price + sqrt_bedrooms + sqrt_bathrooms + sqrt_sqft_lot + sqrt_zipcode + sqrt_view + sqrt_floors + sqrt_sqft_living, data = kc_cleanData_df)

## Number of Bedroom vs Price
qplot(kc_cleanData_df$bedrooms, kc_cleanData_df$price,  data=kc_cleanData_df)
cor.test(kc_cleanData_df$bedrooms, kc_cleanData_df$price)

## Number of Bathrooms vs Price
qplot(kc_cleanData_df$bathrooms, kc_cleanData_df$price,data=kc_cleanData_df)
cor.test(kc_cleanData_df$bathrooms, kc_cleanData_df$price)

## sqft_lot of Bedroom vs Price
qplot(kc_cleanData_df$sqft_lot, kc_cleanData_df$price,  data=kc_cleanData_df)
cor.test(kc_cleanData_df$sqft_lot, kc_cleanData_df$price)

## zipcode vs price
qplot(kc_cleanData_df$zipcode,  kc_cleanData_df$price,   data=kc_cleanData_df)
cor.test(kc_cleanData_df$zipcode, kc_cleanData_df$price)

## view of Bedroom vs Price
qplot(kc_cleanData_df$view, kc_cleanData_df$price,  data=kc_cleanData_df)
cor.test(kc_cleanData_df$view, kc_cleanData_df$price)

## floors vs price
qplot(kc_cleanData_df$floors,  kc_cleanData_df$price,   data=kc_cleanData_df)
cor.test(kc_cleanData_df$floors, kc_cleanData_df$price)

## sqft_living vs Price
qplot(kc_cleanData_df$sqft_living, kc_cleanData_df$price,  data=kc_cleanData_df)
cor.test(kc_cleanData_df$sqft_living, kc_cleanData_df$price)

## sqft_living vs Price
qplot(kc_cleanData_df$yr_built, kc_cleanData_df$price,  data=kc_cleanData_df)
cor.test(kc_cleanData_df$yr_built, kc_cleanData_df$price)
```

```{r model 1 }
## model 1: using multi regression with two categorial variables (bathrooms number and sqft living)
model_1 <- lm(kc_cleanData_df$price ~ kc_cleanData_df$bathrooms + kc_cleanData_df$sqft_living , data = kc_cleanData_df)
summary(model_1)

model_1_PI = predict(kc_cleanData_df.lm, interval="predict", newdata=kc_cleanData_df)
#model_1_PI

```
```{r model 1 residual analysis}
##plotting the model fit
par(mfrow=c(2,2))
plot(model_1 , which=c(1:3))

##Histogram with normal curve
##Store studentized residuals
model_1_studresbrain <- rstudent(model_1 )

##Histogram
hist(model_1_studresbrain, freq=FALSE, main="Distribution of Studentized Residuals(Model 1) ",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))

##Create range of x-values for normal curve
xfit2 <- seq(min(model_1_studresbrain)-1, max(studresbrain)+1, length=40)

##Generate values from the normal distribution at the specified values
yfit2 <- (dnorm(xfit2))

##Add the normal curve
lines(xfit2, yfit2, ylim=c(0,0.5))

```
## model 2
```{r evaluating/validating Models}
library(ggplot2)

## adjusted R^2 - higher is better
## MSPE (Mean Square Prediction Error) - lower is better as it measure the distance the prediction are from the acutual value

## Read in the CSV file
kc_data_df <- read.csv(file="C:/Users/chiawa/DS6372Project1_Group5/kc_house_data.csv", header=TRUE, sep=",")

## Remove all the NAs
kc_cleanData_df <-kc_data_df[rowSums(is.na(kc_data_df)) == 0,]
kc_cleanData_df.lm <- lm(kc_cleanData_df$price ~ kc_cleanData_df$bathrooms + kc_cleanData_df$sqft_living , data = kc_cleanData_df)

## 1. Divide the data set wtih responses into a "Training set" and a "Test set"

## 2. Train a model on the Training set.

## 3. Generate prediction using this model for the test set explanatory variables

## 4. Find the MSPE using the predictions and the actual value from the test set.

## 5. Repeat 2-4 for competing models.

## 6. compare MSPEs of Competing models.

```

## Object 2: Anova

You can also embed plots, for example:

```{r correlation, echo=FALSE}
# compare models
#model 1 <- lm(y ~ x1 + x2 + x3 + x4, data=mydata)
#model 2 <- lm(y ~ x1 + x2)
#anova(model 1, model 22)


```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
